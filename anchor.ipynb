{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d404e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license\n",
    "\"\"\"\n",
    "AutoAnchor utils\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import TryExcept\n",
    "from utils.general import LOGGER, TQDM_BAR_FORMAT, colorstr\n",
    "PREFIX = colorstr('AutoAnchor: ')\n",
    "def check_anchor_order(m):\n",
    "    # Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary\n",
    "    a = m.anchors.prod(-1).mean(-1).view(-1)  # mean anchor area per output layer\n",
    "    da = a[-1] - a[0]  # delta a\n",
    "    ds = m.stride[-1] - m.stride[0]  # delta s\n",
    "    if da and (da.sign() != ds.sign()):  # same order\n",
    "        LOGGER.info(f'{PREFIX}Reversing anchor order')\n",
    "        m.anchors[:] = m.anchors.flip(0)\n",
    "\n",
    "\n",
    "@TryExcept(f'{PREFIX}ERROR')\n",
    "def check_anchors(\n",
    "    , model, thr=4.0, imgsz=640):\n",
    "    # Check anchor fit to data, recompute if necessary\n",
    "    m = model.module.model[-1] if hasattr(model, 'module') else model.model[-1]  # Detect()\n",
    "    shapes = imgsz * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n",
    "    scale = np.random.uniform(0.9, 1.1, size=(shapes.shape[0], 1))  # augment scale\n",
    "    wh = torch.tensor(np.concatenate([l[:, 3:5] * s for s, l in zip(shapes * scale, dataset.labels)])).float()  # wh\n",
    "\n",
    "    def metric(k):  # compute metric\n",
    "        r = wh[:, None] / k[None]\n",
    "        x = torch.min(r, 1 / r).min(2)[0]  # ratio metric\n",
    "        best = x.max(1)[0]  # best_x\n",
    "        aat = (x > 1 / thr).float().sum(1).mean()  # anchors above threshold\n",
    "        bpr = (best > 1 / thr).float().mean()  # best possible recall\n",
    "        return bpr, aat\n",
    "\n",
    "    stride = m.stride.to(m.anchors.device).view(-1, 1, 1)  # model strides\n",
    "    anchors = m.anchors.clone() * stride  # current anchors\n",
    "    bpr, aat = metric(anchors.cpu().view(-1, 2))\n",
    "    s = f'\\n{PREFIX}{aat:.2f} anchors/target, {bpr:.3f} Best Possible Recall (BPR). '\n",
    "    if bpr > 0.98:  # threshold to recompute\n",
    "        LOGGER.info(f'{s}Current anchors are a good fit to dataset âœ…')\n",
    "    else:\n",
    "        LOGGER.info(f'{s}Anchors are a poor fit to dataset âš ï¸, attempting to improve...')\n",
    "        na = m.anchors.numel() // 2  # number of anchors\n",
    "        #na = 20\n",
    "        anchors = kmean_anchors(dataset, n=na, img_size=imgsz, thr=thr, gen=1000, verbose=False)\n",
    "        new_bpr = metric(anchors)[0]\n",
    "        if new_bpr > bpr:  # replace anchors\n",
    "            anchors = torch.tensor(anchors, device=m.anchors.device).type_as(m.anchors)\n",
    "            m.anchors[:] = anchors.clone().view_as(m.anchors)\n",
    "            check_anchor_order(m)  # must be in pixel-space (not grid-space)\n",
    "            m.anchors /= stride\n",
    "            s = f'{PREFIX}Done âœ… (optional: update model *.yaml to use these anchors in the future)'\n",
    "        else:\n",
    "            s = f'{PREFIX}Done âš ï¸ (original anchors better than new anchors, proceeding with original anchors)'\n",
    "        LOGGER.info(s)\n",
    "\n",
    "\n",
    "def kmean_anchors(dataset='./data/coco128.yaml', n=9, img_size=640, thr=4.0, gen=1000, verbose=True):\n",
    "    \"\"\" Creates kmeans-evolved anchors from training dataset\n",
    "\n",
    "        Arguments:\n",
    "            dataset: path to data.yaml, or a loaded dataset\n",
    "            n: number of anchors\n",
    "            img_size: image size used for training\n",
    "            thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0\n",
    "            gen: generations to evolve anchors using genetic algorithm\n",
    "            verbose: print all results\n",
    "\n",
    "        Return:\n",
    "            k: kmeans evolved anchors\n",
    "\n",
    "        Usage:\n",
    "            from utils.autoanchor import *; _ = kmean_anchors()\n",
    "    \"\"\"\n",
    "    from scipy.cluster.vq import kmeans\n",
    "\n",
    "    npr = np.random\n",
    "    thr = 1 / thr\n",
    "\n",
    "    def metric(k, wh):  # compute metrics\n",
    "        r = wh[:, None] / k[None]\n",
    "        x = torch.min(r, 1 / r).min(2)[0]  # ratio metric\n",
    "        # x = wh_iou(wh, torch.tensor(k))  # iou metric\n",
    "        return x, x.max(1)[0]  # x, best_x\n",
    "\n",
    "    def anchor_fitness(k):  # mutation fitness\n",
    "        _, best = metric(torch.tensor(k, dtype=torch.float32), wh)\n",
    "        return (best * (best > thr).float()).mean()  # fitness\n",
    "\n",
    "    def print_results(k, verbose=True):\n",
    "        k = k[np.argsort(k.prod(1))]  # sort small to large\n",
    "        x, best = metric(k, wh0)\n",
    "        bpr, aat = (best > thr).float().mean(), (x > thr).float().mean() * n  # best possible recall, anch > thr\n",
    "        s = f'{PREFIX}thr={thr:.2f}: {bpr:.4f} best possible recall, {aat:.2f} anchors past thr\\n' \\\n",
    "            f'{PREFIX}n={n}, img_size={img_size}, metric_all={x.mean():.3f}/{best.mean():.3f}-mean/best, ' \\\n",
    "            f'past_thr={x[x > thr].mean():.3f}-mean: '\n",
    "        for x in k:\n",
    "            s += '%i,%i, ' % (round(x[0]), round(x[1]))\n",
    "        if verbose:\n",
    "            LOGGER.info(s[:-2])\n",
    "        return k\n",
    "\n",
    "    if isinstance(dataset, str):  # *.yaml file\n",
    "        with open(dataset, errors='ignore') as f:\n",
    "            data_dict = yaml.safe_load(f)  # model dict\n",
    "        from utils.dataloaders import LoadImagesAndLabels\n",
    "        dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)\n",
    "\n",
    "    # Get label wh\n",
    "    shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)\n",
    "    wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh\n",
    "\n",
    "    # Filter\n",
    "    i = (wh0 < 3.0).any(1).sum()\n",
    "    if i:\n",
    "        LOGGER.info(f'{PREFIX}WARNING âš ï¸ Extremely small objects found: {i} of {len(wh0)} labels are <3 pixels in size')\n",
    "    wh = wh0[(wh0 >= 2.0).any(1)].astype(np.float32)  # filter > 2 pixels\n",
    "    # wh = wh * (npr.rand(wh.shape[0], 1) * 0.9 + 0.1)  # multiply by random scale 0-1\n",
    "\n",
    "    # Kmeans init\n",
    "    try:\n",
    "        LOGGER.info(f'{PREFIX}Running kmeans for {n} anchors on {len(wh)} points...')\n",
    "        assert n <= len(wh)  # apply overdetermined constraint\n",
    "        s = wh.std(0)  # sigmas for whitening\n",
    "        k = kmeans(wh / s, n, iter=30)[0] * s  # points\n",
    "        assert n == len(k)  # kmeans may return fewer points than requested if wh is insufficient or too similar\n",
    "    except Exception:\n",
    "        LOGGER.warning(f'{PREFIX}WARNING âš ï¸ switching strategies from kmeans to random init')\n",
    "        k = np.sort(npr.rand(n * 2)).reshape(n, 2) * img_size  # random init\n",
    "    wh, wh0 = (torch.tensor(x, dtype=torch.float32) for x in (wh, wh0))\n",
    "    k = print_results(k, verbose=False)\n",
    "    #Plot\n",
    "    k, d = [None] * 20, [None] * 20\n",
    "    for i in tqdm(range(1, 21)):\n",
    "        k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance\n",
    "    ig, ax = plt.subplots(1, 2, figsize=(14, 7), tight_layout=True)\n",
    "    ax = ax.ravel()\n",
    "    #ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh\n",
    "    ax[0].hist(wh[wh[:, 0]<100, 0],400)\n",
    "    ax[1].hist(wh[wh[:, 1]<100, 1],400)\n",
    "    fig.savefig('wh.png', dpi=200)\n",
    "    plt.show()\n",
    "\n",
    "    # Evolve\n",
    "    f, sh, mp, s = anchor_fitness(k), k.shape, 0.9, 0.1  # fitness, generations, mutation prob, sigma\n",
    "    pbar = tqdm(range(gen), bar_format=TQDM_BAR_FORMAT)  # progress bar\n",
    "    for _ in pbar:\n",
    "        v = np.ones(sh)\n",
    "        while (v == 1).all():  # mutate until a change occurs (prevent duplicates)\n",
    "            v = ((npr.random(sh) < mp) * random.random() * npr.randn(*sh) * s + 1).clip(0.3, 3.0)\n",
    "        kg = (k.copy() * v).clip(min=2.0)\n",
    "        fg = anchor_fitness(kg)\n",
    "        if fg > f:\n",
    "            f, k = fg, kg.copy()\n",
    "            pbar.desc = f'{PREFIX}Evolving anchors with Genetic Algorithm: fitness = {f:.4f}'\n",
    "            if verbose:\n",
    "                print_results(k, verbose)\n",
    "\n",
    "    return print_results(k).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74077d29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
